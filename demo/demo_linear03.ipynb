{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear regression with multiple features and multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.81085013  1.65990317 -0.69234685 -1.16663094 -1.97535614]\n",
      " [-1.43099953  0.20949484 -0.55380229  0.28532619 -0.73233353]\n",
      " [ 0.13188025 -2.1255861   1.01701509 -1.14572007 -0.89678116]\n",
      " [-0.50882966  0.00709968  0.75296069 -0.13249528  0.4259629 ]]\n",
      "X shape =  (200, 5)\n",
      "W shape =  (5, 2)\n",
      "b shape =  (2,)\n",
      "Target shape =  (200, 2)\n",
      "Y shape =  (200, 2)\n"
     ]
    }
   ],
   "source": [
    "N_OBSERVATIONS = 200\n",
    "N_FEATURES = 5\n",
    "N_OUTPUS = 2\n",
    "\n",
    "# Generate random data for inputs & outputs\n",
    "X = np.random.randn(N_OBSERVATIONS, N_FEATURES)\n",
    "print(X[:4, :])\n",
    "print('X shape = ', X.shape)\n",
    "W0 = np.array([[1, 2.5], [2., 0.4], [10., -6.], [-7., 4.], [3.0, 0.]])\n",
    "b0 = np.array([4.5, -3.5])\n",
    "print('W shape = ', W0.shape)\n",
    "print('b shape = ', b0.shape)\n",
    "\n",
    "targets = np.dot(X, W0) + b0\n",
    "print('Target shape = ', targets.shape)\n",
    "# Generate random outputs\n",
    "Y = np.dot(X, W0) + b0 + np.random.uniform(-1, 1, size=(N_OBSERVATIONS, N_OUTPUS))\n",
    "print('Y shape = ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 258.78747164732516\n",
      "Epoch 10: loss = 61.784657417052095\n",
      "Epoch 20: loss = 39.03015774840027\n",
      "Epoch 30: loss = 36.05355474373889\n",
      "Epoch 40: loss = 35.61766027732264\n",
      "Epoch 50: loss = 35.54688394061347\n",
      "Epoch 60: loss = 35.53439559873554\n",
      "Epoch 70: loss = 35.53205579130054\n",
      "Epoch 80: loss = 35.53159934738641\n",
      "Epoch 90: loss = 35.531507932694105\n",
      "Epoch 100: loss = 35.53148930916981\n",
      "Epoch 110: loss = 35.53148547207495\n",
      "Epoch 120: loss = 35.531484675439394\n",
      "Epoch 130: loss = 35.5314845091625\n",
      "Epoch 140: loss = 35.531484474323406\n",
      "Epoch 150: loss = 35.53148446700315\n",
      "Epoch 160: loss = 35.53148446546181\n",
      "Epoch 170: loss = 35.531484465136735\n",
      "Epoch 180: loss = 35.5314844650681\n",
      "Epoch 190: loss = 35.53148446505358\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights and biases\n",
    "W = np.random.randn(N_FEATURES, N_OUTPUS)\n",
    "b = np.random.randn(N_OUTPUS)\n",
    "# Train model\n",
    "LEARNING_RATE = 0.05\n",
    "EPOCHS = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    # Forward pass\n",
    "    Y_pred = np.dot(X, W) + b\n",
    "    error = Y_pred - Y\n",
    "    # Compute loss\n",
    "    loss = np.sum(error ** 2) / N_OBSERVATIONS\n",
    "    # Backward pass\n",
    "    grad_Y_pred = 2.0 * (Y_pred - Y)\n",
    "    grad_W = np.dot(X.T, grad_Y_pred)\n",
    "    grad_b = grad_Y_pred.sum(axis=0)\n",
    "    # Update weights and biases\n",
    "    W -= LEARNING_RATE * 2.0 * np.dot(X.T, error) / N_OBSERVATIONS\n",
    "    b -= LEARNING_RATE * 2.0 * np.sum(error) / N_OBSERVATIONS\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss = 35.53148446505065\n",
      "Final W = [[ 0.43217744  3.01606426]\n",
      " [ 2.38478164  0.09054692]\n",
      " [10.58447248 -6.59701429]\n",
      " [-7.38414595  4.37182019]\n",
      " [ 2.92116715  0.08498462]]\n",
      "Final b = [0.19596017 0.78727064]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final loss = {loss}\")\n",
    "print(f\"Final W = {W}\")\n",
    "print(f\"Final b = {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.09994158e-02  2.68239230e+00]\n",
      " [-1.00307500e+01  1.32885253e+00]\n",
      " [ 1.17889820e+01 -1.08017932e+01]\n",
      " [ 1.01853517e+01 -6.25708718e+00]\n",
      " [-4.12444812e+00 -2.41245063e+00]\n",
      " [-9.04707301e+00  1.66017662e+00]\n",
      " [-1.09156895e+01  4.30451488e+00]\n",
      " [ 2.66717957e+01 -1.54533587e+01]\n",
      " [-1.48100544e+00  2.94012056e+00]\n",
      " [-8.44323830e+00  7.10316211e+00]]\n",
      "[[  3.94753615  -1.32135609]\n",
      " [ -6.24431664  -2.5295824 ]\n",
      " [ 15.88055603 -14.70550467]\n",
      " [ 13.74033231  -9.81697958]\n",
      " [  0.05467308  -6.51036357]\n",
      " [ -4.32566793  -2.97162068]\n",
      " [ -6.43838597  -0.18616684]\n",
      " [ 29.3225358  -18.13157344]\n",
      " [  2.94824614  -1.4873842 ]\n",
      " [ -3.37727566   2.08770403]]\n"
     ]
    }
   ],
   "source": [
    "X_test = X[:10, :]\n",
    "Y_test = np.dot(X_test, W) + b\n",
    "print(Y_test)\n",
    "print(targets[:10, :])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
